---
title: Bayesian vs. Frequentist
author: Alireza Behzadnia
date: '2018-03-11'
categories:
  - Bayesian
  - Inference
  - Frequentist
slug: bayesian-vs-frequentist
weight: 1
---

Here we will look at how a Bayesian and frequentist may go about answering a simple inference question:

### Background
As part of our commitment to good medical practice, we decide to conduct a quality assurance audit.

> Good Medical Practice  
> \S 1.13: *"You must take steps to mintor and improve the quality of your work"*  
> \S 2.22: *"You must take part in systems of quality assurance and quality improvement to promote patient safety"*

We decide to audit how frequently cannulas are being changed in the ICU and HDU departments. According to [NICE: Infection prevention and control](https://www.nice.org.uk/guidance/qs61/chapter/quality-statement-5-vascular-access-devices) guidance, an indwelling intravascular catheter used to deliver parenteral nutrition should be changed every 24 hours.

#### Study

In our audit we would like to know how closely our wards adhere to this guidance. After a discussion with colleagues we decide that total adherence can be defined as *P*(cannula changed every 24 hours) > 0.9%; partial adherence *P*(change) >0.8% and anything <0.8 is considered inadequate adherence to the guidelines.

We decide to follow all the patients currently admitted for 24 hours. Due to the small number of admissions requiring parenteral nutrition at our ICU and HDU, our sample size is only 5.

After 24 hours we find: 4 of the patients had their cannula changed.


### Frequentist's Approach:

If we decide to wear the frequentist hat, we first need to set our hypothesis:  

- H~0~ : Our unit does follow the guidline
    - P(cannula change in 24 hours) = 0.90  
- H~a~: Our unit does NOT follow the guideline
    - P(cannula change in 24 hours) < 0.90

We can answer our question using the binomial distribution: 
- We have 5 patients (i.e. **fixed** number of trials; $n=5$)
- The care of each patient is **independent**
    - Although, this may not be realistic to assume; but ideally, healthcare providers treat every patient equally
- We *assume* the probability of success or cannula change in 24 hours to be fixed at 90%.
  
With the binomial requirements meants; we can proceed to use binomial distribution.

- We set out significance level at 0.05 ($\alpha = 0.05$)
    - If the P(patient to not have their cannula changed) is > 0.05, we fail to reject the H~0~.

In other words, if the *p-value* > 0.05, only 9 out of 10 patients in our units have their cannulas changed every 24 hours.

$k = 4, n = 5$
$P(K \leq 4| n=5, p = 0.90)$
```{r}
sum(dbinom(0:4, size = 5, prob = 0.9))
```

Since our *p-value* is greater than $\alpha = 0.05$, we accept the null hypothesis:
  - **H~0~ = our unit does follow the guidance**

#### Bayesian's Approach:
Now let's look at our data through the Bayesian glass.The first strikingly different a Bayesian must do is to set up *hypotheses* instead of a *null hypothesis*:
  - H~1~ = *complete adherence*
  - H~2~ = *partial adherence*
  - H~3~ = *non-adherence*
    - *lets assume, <0.80 ~ 0.70*
  
These hypotheses are in fact our **models** in the Bayesian language. Here, we would like to evaluate the probability of each model being true.

#### Prior
We may or may not have prior probability of each model based on previous audits or pilot studies. In our example, let's assume we don't have any data available. 

In this instance, we would then give equal probability to all the models:

> *P*(H~1~)=*P*(H~2~)=*P*(H~3~)=$\frac{1}{3}$ 

```{r}
models = c(0.9, 0.8, 0.7)
prior = c(rep(1/3, 3))
names(prior) = models
prior
```

#### Likelihood
We can calculate our $P(data|model):
```{r}
likelihood = dbinom(4, size = 5, prob = models)
names(likelihood) = models
likelihood
barplot(likelihood, main = "Likelihood")

```
So far, our 2nd model looks promising.

#### Posteriori
Now, we can update our prioir $P(model|data) =\frac{P(data|model) \times P(model)}{P(data)}$ and 

```{r}
evidence = sum(likelihood * prior)
posterior = (prior * likelihood)/evidence
posterior
barplot(posterior, main = "Posterior")

```

#### conclusion
When looking at unit as a Bayesian, we then would conclude that we are only **partially** following the guidelines.

****

## Who is correct?
The Frequentist is very sensitive to the sample size. *Strength in number!!* 

Let's redo the calculations assuming we've looked at 50 patients when 40 have had their cannula changed within 24 hours.

#### Frequentist
```{r}
sum(dbinom(0:40, size = 50, prob = 0.9))
```
We have to **reject** the null hypothesis!

#### Bayesian
```{r}
models = c(0.9, 0.8, 0.7)
prior = c(rep(1/3, 3))
likelihood = dbinom(40, size = 50, prob = models)
names(likelihood) = models
evidence = sum(likelihood * prior)
posterior = (prior * likelihood)/evidence
posterior
barplot(posterior, main = "Posterior")
```

The second model is clearly the best.